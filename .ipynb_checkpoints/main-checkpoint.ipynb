{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Practical\n",
    "\n",
    "__Overview__\n",
    "\n",
    "Goal of this assignment is to build a deep learning pipeline to predict parameters of a circle ( center (x, y) and radius (r)) embedded in a noisy/occluded image $I_N$. The pipeline delineated in the following sectionscontains 2 key elements:\n",
    "\n",
    "1. The denoising backbone - DnCNN.\n",
    "2. The feature extractor - CDNet.\n",
    "\n",
    "Time taken for modelling the architecture: $\\approx$ 20 minutes and cumulative training time for both the networks: $\\approx$ 2 hours, spread out over a day on an AWS P2 instance.\n",
    "\n",
    "\n",
    "#### Quick links\n",
    "1. [DnCNN]()\n",
    "2. [CDNet]()\n",
    "3. [Results]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The denoising backbone: [DnCNN](https://arxiv.org/pdf/1608.03981.pdf)\n",
    "\n",
    "Inspired from the work by Kai Zhang et. al, the denoising backbone does most of the heavy lifting for CDNet. The denoising network implemented below is a simplified version of the original implementation preserving it's key aspects:\n",
    "1. Batch normalization \n",
    "2. Residual Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# stats\n",
    "import numpy as np\n",
    "# scale\n",
    "import cv_practical as cvp_utils\n",
    "# fancy stuff\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DnCNN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    \"\"\" Module implementing a simplified DnCNN\n",
    "    described in https://arxiv.org/pdf/1608.03981.pdf\n",
    "    \"\"\"\n",
    "    def __init__( self, n_channels=64, image_channels=1,\n",
    "        kernel_size=3, init_weights = True ):\n",
    "        super(DnCNN, self).__init__()\n",
    "        \"\"\"Constructor\n",
    "        \n",
    "        Args:\n",
    "            n_channels: Number of filters for each of the convolution\n",
    "                layers.\n",
    "            image_channels: Number of channels of the input image.\n",
    "            kernel_size: size of each convolutional filter.\n",
    "            init_weights: Initializes the convolutional filters orthogonally\n",
    "                preserving the norm.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.name = \"dncnn\"\n",
    "        self._kernel_size = 3\n",
    "        self._n_channels = 64\n",
    "        self._image_channels = image_channels\n",
    "        self._padding = 1\n",
    "\n",
    "\n",
    "        self.conv_b1 = nn.Conv2d(\n",
    "            in_channels=image_channels,\n",
    "            out_channels=self._n_channels,\n",
    "            kernel_size=self._kernel_size, padding=self._padding, bias=True\n",
    "        )\n",
    "        self.nl_b1 = nn.ReLU( inplace = True )\n",
    "\n",
    "        self.conv_b2 = nn.Conv2d(\n",
    "            in_channels = self._n_channels,\n",
    "            out_channels = self._n_channels,\n",
    "            kernel_size = self._kernel_size,\n",
    "            padding = self._padding, bias=False\n",
    "        )\n",
    "        self.bn_2 = nn.BatchNorm2d(self._n_channels, eps = 1e-4, momentum = 0.95)\n",
    "        self.nl_b2 = nn.ReLU( inplace = True )\n",
    "\n",
    "        self.conv_b3 = nn.Conv2d(\n",
    "            in_channels = self._n_channels,\n",
    "            out_channels = self._n_channels,\n",
    "            kernel_size = self._kernel_size,\n",
    "            padding = self._padding, bias=False\n",
    "        )\n",
    "        self.bn_3 = nn.BatchNorm2d(self._n_channels, eps = 1e-4, momentum = 0.95)\n",
    "        self.nl_b3 = nn.ReLU( inplace = True )\n",
    "\n",
    "\n",
    "        self.conv_b4 = nn.Conv2d(\n",
    "            in_channels = self._n_channels,\n",
    "            out_channels = self._n_channels,\n",
    "            kernel_size = self._kernel_size,\n",
    "            padding = self._padding, bias=False\n",
    "        )\n",
    "        self.bn_4 = nn.BatchNorm2d(self._n_channels, eps = 1e-4, momentum = 0.95)\n",
    "        self.nl_b4 = nn.ReLU( inplace = True )\n",
    "\n",
    "        self.conv_b5 = nn.Conv2d(\n",
    "            in_channels = self._n_channels,\n",
    "            out_channels = self._image_channels,\n",
    "            kernel_size = self._kernel_size,\n",
    "            padding = self._padding,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        if init_weights:\n",
    "            self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = x\n",
    "\n",
    "        out = self.conv_b1(x)\n",
    "        out = self.nl_b1(out)\n",
    "\n",
    "        out = self.conv_b2(out)\n",
    "        out = self.bn_2(out)\n",
    "        out = self.nl_b2(out)\n",
    "\n",
    "        out = self.conv_b3(out)\n",
    "        out = self.bn_3(out)\n",
    "        out = self.nl_b3(out)\n",
    "\n",
    "        out = self.conv_b4(out)\n",
    "        out = self.bn_4(out)\n",
    "        out = self.nl_b4(out)\n",
    "\n",
    "        out = self.conv_b5(out)\n",
    "        \n",
    "        return y - out\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initializes weights and biases for the module.\n",
    "        \n",
    "        Weights for the convolutional layers have been initialized \n",
    "        orthogonally and biases to a constant. \n",
    "        \"\"\"\n",
    "        for mdx, module in enumerate(self.modules()):\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                init.orthogonal_(module.weight)\n",
    "                print('initialized layer: {}'.format(mdx), end='\\r')\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                init.constant_(module.weight, 1)\n",
    "                init.constant_(module.bias, 0)\n",
    "        print(\"initialization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sum of Squared Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSE(_Loss):\n",
    "    \"\"\"\n",
    "    sse = 1/2 * nn.MSELoss (reduced by sum)\n",
    "    \"\"\"\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
    "        super(SSE, self).__init__(\n",
    "            size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
    "        return torch.nn.functional.mse_loss(\n",
    "            input, target, size_average=None, reduce=None, \n",
    "            reduction='sum').div_(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset for training/testing DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNNDataset(torch_data.Dataset):\n",
    "    \"\"\"Dataset for training our simplified DnCNN.\n",
    "    \n",
    "    This dataset inherits from PyTorch torch_data.Dataset \n",
    "    to be used to create batches for PyTorch's dataloader.\n",
    "    Each sample in the dataset is a pair of noisy image (I_n) and\n",
    "    denoised image (I).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, count=1000, noise = 1, \n",
    "                 random_noise = True, debug = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            count: Number of sample image pairs in the dataset.\n",
    "            noise: Max level of gaussian additive noise.\n",
    "            random_noise: If set to True, additive gausian noise \n",
    "                is multiplied by a random constant sampled from a \n",
    "                uniform distruibution in range (0, noise)\n",
    "            debug: If set to True, writes image pairs to disk.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._deubg = debug\n",
    "        self._count = count\n",
    "        self._noise = noise\n",
    "        self._random_noise = random_noise\n",
    "        self._circle_images = []\n",
    "\n",
    "        self.create_dataset()\n",
    "\n",
    "    def create_dataset(self):\n",
    "        for i in range(self._count):\n",
    "            noise = np.random.uniform(0, self._noise) \\\n",
    "                if self._random_noise else self._noise\n",
    "\n",
    "            params, img, img_noise = cvp_utils.noisy_circle(200, 50, noise)\n",
    "            # normalize.\n",
    "            img = (img - np.min(img))/(np.max(img) - np.min(img))\n",
    "            img_noise = (img_noise - np.min(img_noise))/(np.max(img_noise) - np.min(img_noise))\n",
    "            # add a channel axis to conform to\n",
    "            # PyTorch's tensor specifications.\n",
    "            self._circle_images.append(\n",
    "                [\n",
    "                    np.expand_dims(img_noise, axis=0),\n",
    "                    np.expand_dims(img, axis=0)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._circle_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._circle_images[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dncnn(model, optimizer, criterion, device, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    tbar = tqdm(dataloader)\n",
    "    num_samples = len(dataloader)\n",
    "    for i, sample in enumerate(tbar):\n",
    "        image, target = sample[0].float(), sample[1].float()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        tbar.set_description('Train loss:  %.3f' % (train_loss / (i + 1)))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "\n",
    "def validate_dncnn(model, criterion, device, dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    tbar = tqdm(dataloader)\n",
    "    num_samples = len(dataloader)\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(tbar):\n",
    "            image, target = sample[0].float(), sample[1].float()\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            tbar.set_description('Val loss:    %.3f' % (train_loss / (i + 1)))\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "\n",
    "def test_dncnn(model, device, dataloader, debug = False):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    tbar = tqdm(dataloader)\n",
    "    num_samples = len(dataloader)\n",
    "    outputs = []\n",
    "    ious = []\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(tbar):\n",
    "\n",
    "            image = sample[0].float()\n",
    "            image = image.to(device)\n",
    "            outputs.append([sample[0], model(image), sample[1]])\n",
    "    if debug:\n",
    "        for bdx, b in enumerate(outputs):\n",
    "            for idx , i in enumerate(zip(b[0], b[1], b[2])):\n",
    "                img = i[0][0].cpu().numpy()\n",
    "                pred_params = i[1][0].cpu().numpy()\n",
    "                target_params = i[2][0].cpu().numpy()\n",
    "\n",
    "                plt.imsave(\"./results/{}.png\".format(idx), img)\n",
    "                plt.imsave(\"./results/{}_pred.png\".format(idx), pred_params)\n",
    "                plt.imsave(\"./results/{}_targ.png\".format(idx), target_params)\n",
    "\n",
    "                \n",
    "def total_parameters(model):\n",
    "    \"\"\"Get number parameters in a network.\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch nn.Module object.\n",
    "    \n",
    "    Returns:\n",
    "        num_parameters (int): total parameters in a network.\n",
    "    \n",
    "    \"\"\"\n",
    "    model_parameters = filter(\n",
    "        lambda p: p.requires_grad, model.parameters())\n",
    "    \n",
    "    return sum([np.prod(p.size()) for p in model_parameters])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXECUTE THIS AT YOUR OWN RISK. \n",
    "\n",
    "\n",
    "Jupyter notebooks occupy a healthy amount of RAM and training the model via this notebook might crash the PC. use the script `denoise_trainer.py` instead to train on a terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv_practical' has no attribute 'main'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fa16e21b2f2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mrandom_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-50d422f6d4a5>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, count, noise, random_noise, debug)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_circle_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-50d422f6d4a5>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_noise\u001b[0m\u001b[1;33m)\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_noise\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoisy_circle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[1;31m# normalize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv_practical' has no attribute 'main'"
     ]
    }
   ],
   "source": [
    "epochs = 100 # number of trainig epochs\n",
    "# explicitly set device to cuda:0 when pipeline is funtional. \n",
    "# setting device to cpu gives more elaborate error trace.\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_dataset = DnCNNDataset(\n",
    "    count = 10000,\n",
    "    random_noise = False,\n",
    "    noise = 2,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "val_dataset = DnCNNDataset(\n",
    "    count = 1000,\n",
    "    noise = 2,\n",
    "    random_noise = False,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "test_dataset = DnCNNDataset(\n",
    "    count = 1000,\n",
    "    noise = 2,\n",
    "    random_noise = False,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "# PyTorch data loaders.\n",
    "train_dataloader = torch_data.DataLoader(train_dataset, num_workers=0, batch_size=32)\n",
    "val_dataloader = torch_data.DataLoader(val_dataset, num_workers=0, batch_size=32)\n",
    "test_dataloader = torch_data.DataLoader(test_dataset, num_workers=0, batch_size=32)\n",
    "\n",
    "model = DnCNN()\n",
    "print(\"total parameters: {}\".format(total_parameters(model)))\n",
    "model.to(device)\n",
    "\n",
    "# Adam optimizer with initial learning rate of 5e-3\n",
    "# and momentum of 10e-2\n",
    "optimizer = torch.optim.Adam(\n",
    "    lr=0.005, weight_decay=1e-3, params=model.parameters()\n",
    ")\n",
    "\n",
    "# Reducaes LR when validation loss plateaus for 10 epochs.\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "# cost function\n",
    "criterion = SSE()\n",
    "\n",
    "# store train and validation loss in this array\n",
    "# to be used later for graphing and facilitate \n",
    "# hyper-parameter search.\n",
    "train_meta = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_dncnn(model, optimizer, criterion, device, train_dataloader)\n",
    "    val_loss = validate_dncnn(model, criterion, device, val_dataloader)\n",
    "    test_score = test_dncnn(model, device, test_dataloader)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(epoch, train_loss, val_loss, test_score)\n",
    "\n",
    "    train_meta.append(\n",
    "        [train_loss, val_loss, test_score]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    model_save_str = './results/models/{}-{}.{}'.format(\n",
    "        model.name, epoch, \"pth\"\n",
    "    )\n",
    "\n",
    "    torch.save( state,model_save_str )\n",
    "    np.save(\"train_meta_denoiser\", np.array(train_meta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model converged easily with the train a test loss trends shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = lambda a: (a - np.min(a))/(np.max(a) - np.min(a))\n",
    "\n",
    "train_meta = np.load(\"train_meta_denoiser.npy\")\n",
    "\n",
    "plt.plot(min_max(train_meta[:, 0]))\n",
    "plt.plot(min_max(train_meta[:, 1]))\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.title(\"Train and test loss trend for a 100 epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the resluts of denoising the image using trained DnCNN at 70th epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|input|prediction|target|\n",
    "|------|------|------|\n",
    "|![](./results/images/0.png)|![](./results/images/0_pred.png)|![](./results/images/0_targ.png)|\n",
    "|![](./results/images/1.png)|![](./results/images/1_pred.png)|![](./results/images/1_targ.png)|\n",
    "|![](./results/images/2.png)|![](./results/images/2_pred.png)|![](./results/images/2_targ.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting parameters of a noisy circle using CDNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using this denoiser as a backbone for our CDNet. A noisy image will be first input to a trained DnCNN and the resulting putput will be used to predict the circle parameters using a regression based loss - MSELoss in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CDNet Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_planes,\n",
    "        bbone,\n",
    "        bbone_weights = None\n",
    "    ):\n",
    "        super(CDNet, self).__init__()\n",
    "\n",
    "        self.denoiser = bbone\n",
    "\n",
    "        if bbone_weights is not None:\n",
    "            self._init_bbone(bbone_weights)\n",
    "\n",
    "        self.fc1   = nn.Linear(33*33, 20*20)\n",
    "        self.fc2   = nn.Linear(20*20, 20)\n",
    "        self.fc3   = nn.Linear(20, 3)\n",
    "\n",
    "        self.name = \"cdnet\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_dx, c_dx, w, h = x.size()\n",
    "\n",
    "        out = self.denoiser(x)\n",
    "\n",
    "        out = F.avg_pool2d(out, 3, stride=3)\n",
    "        out = F.avg_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = out.view(b_dx, -1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _init_bbone(self, bbone_weights):\n",
    "        weights = torch.load(bbone_weights)\n",
    "        self.denoiser.load_state_dict(weights['model'])\n",
    "\n",
    "        # freeze layers for the denoiser\n",
    "        for module in self.denoiser.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                print('layer frozen.', end='\\r')\n",
    "                for parameters in module.parameters():\n",
    "                    parameters.requires_grad = False\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset for training/testing CDNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIRCLEDataset(torch_data.Dataset):\n",
    "    \"\"\"Dataset for training CDNet.\n",
    "    \n",
    "    This dataset inherits from PyTorch torch_data.Dataset \n",
    "    to be used to create batches for PyTorch's dataloader.\n",
    "    Each sample in the dataset is a pair of noisy image (I_n) and\n",
    "    the parameters of the circle in that image (x, y, r).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, count=1000, noise = 1, \n",
    "                 random_noise = True, debug = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            count: Number of sample image pairs in the dataset.\n",
    "            noise: Max level of gaussian additive noise.\n",
    "            random_noise: If set to True, additive gausian noise \n",
    "                is multiplied by a random constant sampled from a \n",
    "                uniform distruibution in range (0, noise)\n",
    "            debug: If set to True, writes image pairs to disk.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._deubg = debug\n",
    "        self._count = count\n",
    "        self._noise = noise\n",
    "        self._random_noise = random_noise\n",
    "        self._circle_images, self._circle_params = [], []\n",
    "\n",
    "        self.create_dataset()\n",
    "\n",
    "    def create_dataset(self):\n",
    "        for i in range(self._count):\n",
    "            noise = np.random.uniform(0, self._noise) if self._random_noise else self._noise\n",
    "\n",
    "            params, img, img_noise = cvp_utils.noisy_circle(200, 50, noise)\n",
    "            # normalize\n",
    "            img = (img - np.min(img))/(np.max(img) - np.min(img))\n",
    "            # add a channel axis to conform to\n",
    "            # PyTorch's tensor specifications.\n",
    "            self._circle_images.append(\n",
    "                np.expand_dims(img, axis=0)\n",
    "            )\n",
    "            \n",
    "            # normalize params.\n",
    "            self._circle_params.append((np.asarray([\n",
    "                    (params[0]-100)/100.0,\n",
    "                    (params[1]-100)/100.0,\n",
    "                    (params[2]-10)/40.0\n",
    "                ], dtype = np.float32)\n",
    "            ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._circle_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [\n",
    "            self._circle_images[idx], self._circle_params[idx]\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cdnet(model, optimizer, criterion, device, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    tbar = tqdm(dataloader)\n",
    "    num_samples = len(dataloader)\n",
    "    for i, sample in enumerate(tbar):\n",
    "        image, target = sample[0].float(), sample[1].float()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        tbar.set_description('Train loss:  %.3f' % (train_loss / (i + 1)))\n",
    "    return train_loss\n",
    "\n",
    "def validate_cdnet(model, criterion, device, dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    tbar = tqdm(dataloader)\n",
    "    num_samples = len(dataloader)\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(tbar):\n",
    "            image, target = sample[0].float(), sample[1].float()\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            tbar.set_description('Val loss:    %.3f' % (train_loss / (i + 1)))\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def test_cdnet(model, device, dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    tbar = tqdm(dataloader)\n",
    "    num_samples = len(dataloader)\n",
    "    outputs = []\n",
    "    ious = []\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(tbar):\n",
    "\n",
    "            image = sample[0].float()\n",
    "            image = image.to(device)\n",
    "            outputs.append([sample[0], model(image), sample[1]])\n",
    "\n",
    "    for bdx, b in enumerate(outputs):\n",
    "        for idx , i in enumerate(zip(b[0], b[1], b[2])):\n",
    "            img = i[0].cpu().numpy()\n",
    "            pred_params = i[1].cpu().numpy()\n",
    "            pred_params = [\n",
    "                pred_params[0]*100+100,\n",
    "                pred_params[1]*100+100,\n",
    "                pred_params[2]*40+10\n",
    "\n",
    "            ]\n",
    "            target_params = i[2].cpu().numpy()\n",
    "            target_params = [\n",
    "                target_params[0]*100+100,\n",
    "                target_params[1]*100+100,\n",
    "                target_params[2]*40+10\n",
    "\n",
    "            ]\n",
    "\n",
    "            ious.append(cvp_utils.iou(target_params, pred_params))\n",
    "    ious = np.asarray(ious)\n",
    "    return np.mean(ious > 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__N.B.__ While training DnCNN, the ride through the cost valley was smooth and mostly linear, however in case of CDNet the optimizer required a lot of navigating and guiding in form of model restarts and changing learning rate. As a result loading the DnCNN backbone weights using `CDNet._init_bbone()` should be carried out only once while the first training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = CIRCLEDataset(\n",
    "    count=10000,\n",
    "    random_noise=False,\n",
    "    noise=2,\n",
    "    debug=False\n",
    ")\n",
    "val_dataset = CIRCLEDataset(\n",
    "    count=1000,\n",
    "    noise=2,\n",
    "    random_noise=False,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "test_dataset = CIRCLEDataset(\n",
    "    count=1000,\n",
    "    noise=2,\n",
    "    random_noise=False,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "train_dataloader = torch_data.DataLoader(train_dataset, num_workers=0, batch_size=32)\n",
    "val_dataloader = torch_data.DataLoader(val_dataset, num_workers=0, batch_size=32)\n",
    "test_dataloader = torch_data.DataLoader(test_dataset, num_workers=0, batch_size=32)\n",
    "\n",
    "\n",
    "model = CDNet(\n",
    "    in_planes=1,\n",
    "    bbone=DnCNN(),\n",
    ")\n",
    "\n",
    "# use this only for the first run\n",
    "model._init_bbone('./results/models/dncnn-70.pth')\n",
    "model.to(device)\n",
    "\n",
    "print(\"total parameters: {}\".format(total_parameters(model)))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    lr=0.005,\n",
    "    weight_decay=1e-3,\n",
    "    params=filter(lambda p: p.requires_grad, model.parameters())\n",
    ")\n",
    "# uncomment this if the training is being \n",
    "# restarted from a local minimum.\n",
    "\"\"\"\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = 0.000005\n",
    "\"\"\"\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.5, verbose=True\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_meta = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, criterion, device, train_dataloader)\n",
    "    val_loss = validate(model, criterion, device, val_dataloader)\n",
    "    test_score = test(model, device, test_dataloader)\n",
    "\n",
    "    scheduler.step(test_score)\n",
    "\n",
    "    print(epoch, train_loss, val_loss, test_score)\n",
    "\n",
    "    train_meta.append(\n",
    "        [train_loss, val_loss, test_score]\n",
    "    )\n",
    "\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    model_save_str = './results/models/{}-{}.{}'.format(\n",
    "        model.name, epoch, \"pth\"\n",
    "    )\n",
    "\n",
    "    torch.save(state, model_save_str)\n",
    "    np.save(\"train_meta_param\", np.array(train_meta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
